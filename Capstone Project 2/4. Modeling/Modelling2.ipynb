{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('winequality-red-scaled2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>quality</th>\n",
       "      <th>alcohol_low</th>\n",
       "      <th>alcohol_medium</th>\n",
       "      <th>alcohol_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.524431</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>-1.393258</td>\n",
       "      <td>-0.461157</td>\n",
       "      <td>-0.245623</td>\n",
       "      <td>-0.468554</td>\n",
       "      <td>-0.384050</td>\n",
       "      <td>0.584003</td>\n",
       "      <td>1.291872</td>\n",
       "      <td>-0.578561</td>\n",
       "      <td>-0.395722</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>-0.730657</td>\n",
       "      <td>-0.193403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.294063</td>\n",
       "      <td>1.915800</td>\n",
       "      <td>-1.393258</td>\n",
       "      <td>0.056665</td>\n",
       "      <td>0.200094</td>\n",
       "      <td>0.872003</td>\n",
       "      <td>0.604073</td>\n",
       "      <td>0.048737</td>\n",
       "      <td>-0.708395</td>\n",
       "      <td>0.124822</td>\n",
       "      <td>-0.395722</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>-0.730657</td>\n",
       "      <td>-0.193403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.294063</td>\n",
       "      <td>1.259934</td>\n",
       "      <td>-1.188617</td>\n",
       "      <td>-0.165259</td>\n",
       "      <td>0.078535</td>\n",
       "      <td>-0.085537</td>\n",
       "      <td>0.214813</td>\n",
       "      <td>0.155790</td>\n",
       "      <td>-0.321247</td>\n",
       "      <td>-0.051024</td>\n",
       "      <td>-0.395722</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>-0.730657</td>\n",
       "      <td>-0.193403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.664067</td>\n",
       "      <td>-1.363534</td>\n",
       "      <td>1.471711</td>\n",
       "      <td>-0.461157</td>\n",
       "      <td>-0.265883</td>\n",
       "      <td>0.105971</td>\n",
       "      <td>0.394471</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>-0.966495</td>\n",
       "      <td>-0.461331</td>\n",
       "      <td>-0.395722</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>-0.730657</td>\n",
       "      <td>-0.193403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.524431</td>\n",
       "      <td>0.713378</td>\n",
       "      <td>-1.393258</td>\n",
       "      <td>-0.535132</td>\n",
       "      <td>-0.265883</td>\n",
       "      <td>-0.277045</td>\n",
       "      <td>-0.204391</td>\n",
       "      <td>0.584003</td>\n",
       "      <td>1.291872</td>\n",
       "      <td>-0.578561</td>\n",
       "      <td>-0.395722</td>\n",
       "      <td>0.792177</td>\n",
       "      <td>-0.730657</td>\n",
       "      <td>-0.193403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0      -0.524431          0.932000    -1.393258       -0.461157  -0.245623   \n",
       "1      -0.294063          1.915800    -1.393258        0.056665   0.200094   \n",
       "2      -0.294063          1.259934    -1.188617       -0.165259   0.078535   \n",
       "3       1.664067         -1.363534     1.471711       -0.461157  -0.265883   \n",
       "4      -0.524431          0.713378    -1.393258       -0.535132  -0.265883   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0            -0.468554             -0.384050  0.584003  1.291872  -0.578561   \n",
       "1             0.872003              0.604073  0.048737 -0.708395   0.124822   \n",
       "2            -0.085537              0.214813  0.155790 -0.321247  -0.051024   \n",
       "3             0.105971              0.394471  0.691057 -0.966495  -0.461331   \n",
       "4            -0.277045             -0.204391  0.584003  1.291872  -0.578561   \n",
       "\n",
       "    quality  alcohol_low  alcohol_medium  alcohol_high  \n",
       "0 -0.395722     0.792177       -0.730657     -0.193403  \n",
       "1 -0.395722     0.792177       -0.730657     -0.193403  \n",
       "2 -0.395722     0.792177       -0.730657     -0.193403  \n",
       "3 -0.395722     0.792177       -0.730657     -0.193403  \n",
       "4 -0.395722     0.792177       -0.730657     -0.193403  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.193403    1310\n",
       " 5.170560      49\n",
       "Name: alcohol_high, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['alcohol_high'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1359 entries, 0 to 1358\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1359 non-null   float64\n",
      " 1   volatile acidity      1359 non-null   float64\n",
      " 2   citric acid           1359 non-null   float64\n",
      " 3   residual sugar        1359 non-null   float64\n",
      " 4   chlorides             1359 non-null   float64\n",
      " 5   free sulfur dioxide   1359 non-null   float64\n",
      " 6   total sulfur dioxide  1359 non-null   float64\n",
      " 7   density               1359 non-null   float64\n",
      " 8   pH                    1359 non-null   float64\n",
      " 9   sulphates             1359 non-null   float64\n",
      " 10  quality               1359 non-null   float64\n",
      " 11  alcohol_low           1359 non-null   float64\n",
      " 12  alcohol_medium        1359 non-null   float64\n",
      " 13  alcohol_high          1359 non-null   float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 148.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "df['quality'] = labelencoder_y.fit_transform(df['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 1175, 1: 1175})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('quality', axis = 1).values\n",
    "y = df['quality'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (1880, 13)\n",
      "Shape of X_test:  (470, 13)\n",
      "Shape of y_train:  (1880,)\n",
      "Shape of y_test (470,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"Shape of X_train: \",X_train.shape)\n",
    "print(\"Shape of X_test: \", X_test.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE for Balancing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier_lr = LogisticRegression(C=1, fit_intercept=True, max_iter=1000, penalty = 'l2',solver='liblinear')\n",
    "classifier_lr.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:  0.8069148936170214\n",
      "Training set:  0.8095744680851064\n",
      "Test set:  0.7808510638297872\n"
     ]
    }
   ],
   "source": [
    "# Predicting Cross Validation Score\n",
    "\n",
    "cv_lr = cross_val_score(estimator = classifier_lr, X = X_train, y = y_train.ravel(), cv = 10)\n",
    "print(\"CV: \", cv_lr.mean())\n",
    "\n",
    "y_pred_lr_train = classifier_lr.predict(X_train)\n",
    "accuracy_lr_train = accuracy_score(y_train, y_pred_lr_train)\n",
    "print(\"Training set: \", accuracy_lr_train)\n",
    "\n",
    "y_pred_lr_test = classifier_lr.predict(X_test)\n",
    "accuracy_lr_test = accuracy_score(y_test, y_pred_lr_test)\n",
    "print(\"Test set: \", accuracy_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,  60],\n",
       "       [ 43, 195]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_lr = confusion_matrix(y_test, y_pred_lr_test)[0,0]\n",
    "fp_lr = confusion_matrix(y_test, y_pred_lr_test)[0,1]\n",
    "tn_lr = confusion_matrix(y_test, y_pred_lr_test)[1,1]\n",
    "fn_lr = confusion_matrix(y_test, y_pred_lr_test)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_features=4, n_estimators=800,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Classification to the Training se\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rf = RandomForestClassifier(criterion = 'entropy', max_features = 4, n_estimators = 800, random_state=42)\n",
    "classifier_rf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV:  0.9154255319148936\n",
      "Training set:  1.0\n",
      "Test set:  0.9340425531914893\n"
     ]
    }
   ],
   "source": [
    "cv_rf = cross_val_score(estimator = classifier_rf, X = X_train, y = y_train.ravel(), cv = 10)\n",
    "print(\"CV: \", cv_rf.mean())\n",
    "\n",
    "y_pred_rf_train = classifier_rf.predict(X_train)\n",
    "accuracy_rf_train = accuracy_score(y_train, y_pred_rf_train)\n",
    "print(\"Training set: \", accuracy_rf_train)\n",
    "\n",
    "y_pred_rf_test = classifier_rf.predict(X_test)\n",
    "accuracy_rf_test = accuracy_score(y_test, y_pred_rf_test)\n",
    "print(\"Test set: \", accuracy_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[207,  25],\n",
       "       [  6, 232]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_rf = confusion_matrix(y_test, y_pred_rf_test)[0,0]\n",
    "fp_rf = confusion_matrix(y_test, y_pred_rf_test)[0,1]\n",
    "tn_rf = confusion_matrix(y_test, y_pred_rf_test)[1,1]\n",
    "fn_rf = confusion_matrix(y_test, y_pred_rf_test)[1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Xgboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dmatrix = xgb.DMatrix(data=X_train,label=y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "\n",
    "def float_range(start, stop, step):\n",
    "  while start <= stop:\n",
    "    yield float(start)\n",
    "    start += decimal.Decimal(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid = {'learning_rate': [0.05,0.1,0.15,0.20,0.25],\n",
    "'max_depth': [3,4,5,6,8,10,12,15],\n",
    "'min_child_weight':[1,3,5,7],\n",
    "'gamma':[0.0,0.1,0.2,0.3,0.4],\n",
    "'colsample_bytree':[0.3,0.4,0.5,0.7],\n",
    "'n_estimators':[100,200,300]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "gbm = xgb.XGBClassifier(use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    2.7s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:25:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best parameters found:  {'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 12, 'learning_rate': 0.25, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
      "Lowest RMSE found:  0.9883852422274247\n"
     ]
    }
   ],
   "source": [
    "grid_mse = RandomizedSearchCV(gbm,param_distributions=gbm_param_grid,n_iter=5,scoring='roc_auc',n_jobs=-1, cv=5, verbose=3)\n",
    "grid_mse.fit(X, y)\n",
    "print(\"Best parameters found: \",grid_mse.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_best = xgb.XGBClassifier(**grid_mse.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anshu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:25:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.25, max_delta_step=0, max_depth=12,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = gbm_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.40%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
